{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting The Data\n",
    "Brian Bahmanyar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** NOTE:** This notebook will not run without implementing your own get_token function to return a Quandl API token\n",
    "* just use the data from /data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Quandl](https://www.quandl.com) provides free daily financial data which will be used in the analyses to come. They also provide a free, but somewhat lackluster Python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import Quandl\n",
    "from my_token import get_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> get_token is a function that returns my Quandl API token, replace with your information as necessary. Or just use the data below, provided in /data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a function written to serve as a wrapper around Quandl's Python API and provide some needed functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_adj_close(token, tickers, start, end=\"\", ratios=[], log_transforms=[]):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        tickers (list): collection of ticker symbols for which to collect adj. close \n",
    "                daily prices for\n",
    "        start (string, format: 2013-01-01): start date for which to collect prices after\n",
    "        end (string, format: 2013-01-01): optional end date, today if not specified\n",
    "        ratios (list): collection of tuples of tickers from 'tickers' list to calculate \n",
    "                price ratios for (the stock with larger mean is numerator)\n",
    "        log_transforms (list): collection of tickers from 'tickers' to include additional \n",
    "                natural log transformed copies\n",
    "    \n",
    "    Returns (dataframe): all adj. close prices, ratios, and log transforms specified\n",
    "    \"\"\" \n",
    "    result = {}\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        try:\n",
    "            result[ticker] = Quandl.get('WIKI/'+ticker, trim_start=start, trim_end=end, authtoken=token)['Adj. Close']\n",
    "        except DatasetNotFound:\n",
    "            print('ERROR:')\n",
    "            print(ticker, 'is not a vaild ticker')\n",
    "\n",
    "    for ratio in ratios:\n",
    "        try:\n",
    "            ticker1, ticker2 = ratio\n",
    "            if result[ticker1].mean() > result[ticker2].mean():\n",
    "                result[ticker1+'/'+ticker2] = result[ticker1]/result[ticker2]\n",
    "            else:\n",
    "                result[ticker2+'/'+ticker1] = result[ticker2]/result[ticker1]\n",
    "        except KeyError:\n",
    "            print('ERROR:')\n",
    "            print(ticker1, 'or', ticker2, 'are not in the list of specified tickers')\n",
    "    \n",
    "    for log_transform in log_transforms:\n",
    "        try:\n",
    "            result['ln('+log_transform+')'] = np.log(result[log_transform])\n",
    "        except KeyError:\n",
    "            print('ERROR:')\n",
    "            print(log_transform, 'is not in the list of specified tickers')\n",
    "    \n",
    "    return pd.DataFrame(result).dropna() # drop na here because of differences in lenght of history for stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> A copy of this function is placed into api_wrapper.py for use in other notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now to Get the Data We Need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tech_bundle = get_adj_close(get_token(),\n",
    "                            ['FB', 'AMZN', 'AAPL'], \n",
    "                            start='2013-01-01', \n",
    "                            ratios=[('FB','AMZN'), ('FB','AAPL'), ('AMZN','AAPL')],\n",
    "                            log_transforms=['FB', 'AMZN', 'AAPL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pairs_bundle = get_adj_close(get_token(),\n",
    "                            ['VZ', 'T', 'KO', 'PEP', 'XOM', 'CVX'], \n",
    "                            start='1990-01-01', \n",
    "                            ratios=[('VZ','T'), ('KO','PEP'), ('XOM','CVX')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAPL/FB</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>AMZN/AAPL</th>\n",
       "      <th>AMZN/FB</th>\n",
       "      <th>FB</th>\n",
       "      <th>ln(AAPL)</th>\n",
       "      <th>ln(AMZN)</th>\n",
       "      <th>ln(FB)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>73.295822</td>\n",
       "      <td>2.617708</td>\n",
       "      <td>257.31</td>\n",
       "      <td>3.510568</td>\n",
       "      <td>9.189643</td>\n",
       "      <td>28.00</td>\n",
       "      <td>4.294504</td>\n",
       "      <td>5.550282</td>\n",
       "      <td>3.332205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>72.370116</td>\n",
       "      <td>2.606054</td>\n",
       "      <td>258.48</td>\n",
       "      <td>3.571640</td>\n",
       "      <td>9.307886</td>\n",
       "      <td>27.77</td>\n",
       "      <td>4.281793</td>\n",
       "      <td>5.554818</td>\n",
       "      <td>3.323956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>70.354805</td>\n",
       "      <td>2.446273</td>\n",
       "      <td>259.15</td>\n",
       "      <td>3.683473</td>\n",
       "      <td>9.010779</td>\n",
       "      <td>28.76</td>\n",
       "      <td>4.253551</td>\n",
       "      <td>5.557407</td>\n",
       "      <td>3.358986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-07</th>\n",
       "      <td>69.940953</td>\n",
       "      <td>2.377327</td>\n",
       "      <td>268.46</td>\n",
       "      <td>3.838381</td>\n",
       "      <td>9.125085</td>\n",
       "      <td>29.42</td>\n",
       "      <td>4.247651</td>\n",
       "      <td>5.592702</td>\n",
       "      <td>3.381675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-08</th>\n",
       "      <td>70.129189</td>\n",
       "      <td>2.413255</td>\n",
       "      <td>266.38</td>\n",
       "      <td>3.798418</td>\n",
       "      <td>9.166552</td>\n",
       "      <td>29.06</td>\n",
       "      <td>4.250339</td>\n",
       "      <td>5.584924</td>\n",
       "      <td>3.369363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AAPL   AAPL/FB    AMZN  AMZN/AAPL   AMZN/FB     FB  ln(AAPL)  \\\n",
       "Date                                                                            \n",
       "2013-01-02  73.295822  2.617708  257.31   3.510568  9.189643  28.00  4.294504   \n",
       "2013-01-03  72.370116  2.606054  258.48   3.571640  9.307886  27.77  4.281793   \n",
       "2013-01-04  70.354805  2.446273  259.15   3.683473  9.010779  28.76  4.253551   \n",
       "2013-01-07  69.940953  2.377327  268.46   3.838381  9.125085  29.42  4.247651   \n",
       "2013-01-08  70.129189  2.413255  266.38   3.798418  9.166552  29.06  4.250339   \n",
       "\n",
       "            ln(AMZN)    ln(FB)  \n",
       "Date                            \n",
       "2013-01-02  5.550282  3.332205  \n",
       "2013-01-03  5.554818  3.323956  \n",
       "2013-01-04  5.557407  3.358986  \n",
       "2013-01-07  5.592702  3.381675  \n",
       "2013-01-08  5.584924  3.369363  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tech_bundle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CVX</th>\n",
       "      <th>CVX/XOM</th>\n",
       "      <th>KO</th>\n",
       "      <th>PEP</th>\n",
       "      <th>PEP/KO</th>\n",
       "      <th>T</th>\n",
       "      <th>VZ</th>\n",
       "      <th>VZ/T</th>\n",
       "      <th>XOM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1990-01-02</th>\n",
       "      <td>6.724925</td>\n",
       "      <td>0.864271</td>\n",
       "      <td>2.791292</td>\n",
       "      <td>6.310486</td>\n",
       "      <td>2.260776</td>\n",
       "      <td>6.506971</td>\n",
       "      <td>12.543602</td>\n",
       "      <td>1.927718</td>\n",
       "      <td>7.781034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-03</th>\n",
       "      <td>6.622892</td>\n",
       "      <td>0.859756</td>\n",
       "      <td>2.753444</td>\n",
       "      <td>6.249591</td>\n",
       "      <td>2.269736</td>\n",
       "      <td>6.393413</td>\n",
       "      <td>12.516094</td>\n",
       "      <td>1.957655</td>\n",
       "      <td>7.703223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-04</th>\n",
       "      <td>6.530134</td>\n",
       "      <td>0.856365</td>\n",
       "      <td>2.743982</td>\n",
       "      <td>6.187714</td>\n",
       "      <td>2.255012</td>\n",
       "      <td>6.272066</td>\n",
       "      <td>12.061367</td>\n",
       "      <td>1.923029</td>\n",
       "      <td>7.625413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-05</th>\n",
       "      <td>6.437377</td>\n",
       "      <td>0.848530</td>\n",
       "      <td>2.715596</td>\n",
       "      <td>6.102264</td>\n",
       "      <td>2.247118</td>\n",
       "      <td>5.969798</td>\n",
       "      <td>11.785666</td>\n",
       "      <td>1.974215</td>\n",
       "      <td>7.586508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990-01-08</th>\n",
       "      <td>6.502307</td>\n",
       "      <td>0.844102</td>\n",
       "      <td>2.772368</td>\n",
       "      <td>6.212268</td>\n",
       "      <td>2.240780</td>\n",
       "      <td>6.070554</td>\n",
       "      <td>11.882713</td>\n",
       "      <td>1.957435</td>\n",
       "      <td>7.703223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 CVX   CVX/XOM        KO       PEP    PEP/KO         T  \\\n",
       "Date                                                                     \n",
       "1990-01-02  6.724925  0.864271  2.791292  6.310486  2.260776  6.506971   \n",
       "1990-01-03  6.622892  0.859756  2.753444  6.249591  2.269736  6.393413   \n",
       "1990-01-04  6.530134  0.856365  2.743982  6.187714  2.255012  6.272066   \n",
       "1990-01-05  6.437377  0.848530  2.715596  6.102264  2.247118  5.969798   \n",
       "1990-01-08  6.502307  0.844102  2.772368  6.212268  2.240780  6.070554   \n",
       "\n",
       "                   VZ      VZ/T       XOM  \n",
       "Date                                       \n",
       "1990-01-02  12.543602  1.927718  7.781034  \n",
       "1990-01-03  12.516094  1.957655  7.703223  \n",
       "1990-01-04  12.061367  1.923029  7.625413  \n",
       "1990-01-05  11.785666  1.974215  7.586508  \n",
       "1990-01-08  11.882713  1.957435  7.703223  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_bundle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tech_bundle.to_csv('data/tech_bundle.csv')\n",
    "# pairs_bundle.to_csv('data/pairs_bundle.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
